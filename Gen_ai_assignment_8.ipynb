{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY3LL8q5KeBBBSWpLkYU1E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navaneethkomuravelli/GenAI_2303A52374/blob/main/Gen_ai_assignment_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "18YznQf987Cu",
        "outputId": "218688eb-2cbd-45f7-c3ac-ab264c037b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4564 - loss: 0.8320 - val_accuracy: 0.4250 - val_loss: 0.8456\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4706 - loss: 0.8230 - val_accuracy: 0.4250 - val_loss: 0.8452\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4508 - loss: 0.8339 - val_accuracy: 0.4250 - val_loss: 0.8448\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4453 - loss: 0.8351 - val_accuracy: 0.4250 - val_loss: 0.8444\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4455 - loss: 0.8397 - val_accuracy: 0.4250 - val_loss: 0.8441\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4519 - loss: 0.8198 - val_accuracy: 0.4219 - val_loss: 0.8437\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4415 - loss: 0.8482 - val_accuracy: 0.4219 - val_loss: 0.8433\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4527 - loss: 0.8344 - val_accuracy: 0.4219 - val_loss: 0.8429\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4515 - loss: 0.8185 - val_accuracy: 0.4219 - val_loss: 0.8425\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4519 - loss: 0.8247 - val_accuracy: 0.4219 - val_loss: 0.8421\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4578 - loss: 0.8176 - val_accuracy: 0.4219 - val_loss: 0.8417\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4596 - loss: 0.8281 - val_accuracy: 0.4219 - val_loss: 0.8413\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4372 - loss: 0.8488 - val_accuracy: 0.4219 - val_loss: 0.8409\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4710 - loss: 0.8076 - val_accuracy: 0.4219 - val_loss: 0.8405\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4415 - loss: 0.8334 - val_accuracy: 0.4219 - val_loss: 0.8401\n",
            "Epoch 16/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4666 - loss: 0.8219 - val_accuracy: 0.4219 - val_loss: 0.8397\n",
            "Epoch 17/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4632 - loss: 0.8146 - val_accuracy: 0.4219 - val_loss: 0.8393\n",
            "Epoch 18/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4425 - loss: 0.8235 - val_accuracy: 0.4219 - val_loss: 0.8388\n",
            "Epoch 19/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4525 - loss: 0.8127 - val_accuracy: 0.4219 - val_loss: 0.8384\n",
            "Epoch 20/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4622 - loss: 0.8174 - val_accuracy: 0.4219 - val_loss: 0.8380\n",
            "Epoch 21/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4501 - loss: 0.8276 - val_accuracy: 0.4219 - val_loss: 0.8376\n",
            "Epoch 22/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4684 - loss: 0.8146 - val_accuracy: 0.4219 - val_loss: 0.8371\n",
            "Epoch 23/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4641 - loss: 0.8132 - val_accuracy: 0.4250 - val_loss: 0.8367\n",
            "Epoch 24/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4701 - loss: 0.8137 - val_accuracy: 0.4250 - val_loss: 0.8363\n",
            "Epoch 25/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4387 - loss: 0.8219 - val_accuracy: 0.4250 - val_loss: 0.8358\n",
            "Epoch 26/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4630 - loss: 0.8103 - val_accuracy: 0.4281 - val_loss: 0.8354\n",
            "Epoch 27/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4483 - loss: 0.8271 - val_accuracy: 0.4281 - val_loss: 0.8350\n",
            "Epoch 28/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4642 - loss: 0.7994 - val_accuracy: 0.4281 - val_loss: 0.8345\n",
            "Epoch 29/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4442 - loss: 0.8206 - val_accuracy: 0.4281 - val_loss: 0.8341\n",
            "Epoch 30/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4535 - loss: 0.8206 - val_accuracy: 0.4281 - val_loss: 0.8336\n",
            "Epoch 31/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4532 - loss: 0.8217 - val_accuracy: 0.4281 - val_loss: 0.8332\n",
            "Epoch 32/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4704 - loss: 0.8058 - val_accuracy: 0.4281 - val_loss: 0.8327\n",
            "Epoch 33/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4555 - loss: 0.8207 - val_accuracy: 0.4281 - val_loss: 0.8323\n",
            "Epoch 34/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4551 - loss: 0.8133 - val_accuracy: 0.4281 - val_loss: 0.8319\n",
            "Epoch 35/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4746 - loss: 0.7989 - val_accuracy: 0.4281 - val_loss: 0.8314\n",
            "Epoch 36/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4563 - loss: 0.8061 - val_accuracy: 0.4281 - val_loss: 0.8310\n",
            "Epoch 37/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4507 - loss: 0.8137 - val_accuracy: 0.4281 - val_loss: 0.8305\n",
            "Epoch 38/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4762 - loss: 0.7923 - val_accuracy: 0.4281 - val_loss: 0.8301\n",
            "Epoch 39/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4718 - loss: 0.7919 - val_accuracy: 0.4281 - val_loss: 0.8296\n",
            "Epoch 40/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4428 - loss: 0.8195 - val_accuracy: 0.4281 - val_loss: 0.8291\n",
            "Epoch 41/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4460 - loss: 0.8174 - val_accuracy: 0.4281 - val_loss: 0.8287\n",
            "Epoch 42/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4683 - loss: 0.8072 - val_accuracy: 0.4281 - val_loss: 0.8282\n",
            "Epoch 43/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4604 - loss: 0.8044 - val_accuracy: 0.4281 - val_loss: 0.8278\n",
            "Epoch 44/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4682 - loss: 0.7925 - val_accuracy: 0.4281 - val_loss: 0.8273\n",
            "Epoch 45/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4520 - loss: 0.8050 - val_accuracy: 0.4281 - val_loss: 0.8269\n",
            "Epoch 46/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4514 - loss: 0.8134 - val_accuracy: 0.4281 - val_loss: 0.8264\n",
            "Epoch 47/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4533 - loss: 0.8102 - val_accuracy: 0.4281 - val_loss: 0.8260\n",
            "Epoch 48/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4727 - loss: 0.7885 - val_accuracy: 0.4281 - val_loss: 0.8255\n",
            "Epoch 49/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4634 - loss: 0.8080 - val_accuracy: 0.4281 - val_loss: 0.8251\n",
            "Epoch 50/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4411 - loss: 0.8206 - val_accuracy: 0.4281 - val_loss: 0.8246\n",
            "Epoch 51/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4847 - loss: 0.8063 - val_accuracy: 0.4281 - val_loss: 0.8242\n",
            "Epoch 52/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4609 - loss: 0.7990 - val_accuracy: 0.4281 - val_loss: 0.8237\n",
            "Epoch 53/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4451 - loss: 0.8046 - val_accuracy: 0.4281 - val_loss: 0.8232\n",
            "Epoch 54/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4632 - loss: 0.8117 - val_accuracy: 0.4281 - val_loss: 0.8228\n",
            "Epoch 55/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4765 - loss: 0.7914 - val_accuracy: 0.4281 - val_loss: 0.8223\n",
            "Epoch 56/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4364 - loss: 0.8278 - val_accuracy: 0.4281 - val_loss: 0.8219\n",
            "Epoch 57/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4736 - loss: 0.7913 - val_accuracy: 0.4281 - val_loss: 0.8214\n",
            "Epoch 58/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4634 - loss: 0.8005 - val_accuracy: 0.4281 - val_loss: 0.8210\n",
            "Epoch 59/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4571 - loss: 0.7983 - val_accuracy: 0.4281 - val_loss: 0.8205\n",
            "Epoch 60/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4518 - loss: 0.8030 - val_accuracy: 0.4281 - val_loss: 0.8200\n",
            "Epoch 61/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4736 - loss: 0.7977 - val_accuracy: 0.4281 - val_loss: 0.8196\n",
            "Epoch 62/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4589 - loss: 0.7988 - val_accuracy: 0.4281 - val_loss: 0.8191\n",
            "Epoch 63/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4388 - loss: 0.7998 - val_accuracy: 0.4281 - val_loss: 0.8187\n",
            "Epoch 64/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4541 - loss: 0.8135 - val_accuracy: 0.4281 - val_loss: 0.8182\n",
            "Epoch 65/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4521 - loss: 0.8035 - val_accuracy: 0.4281 - val_loss: 0.8178\n",
            "Epoch 66/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4671 - loss: 0.7905 - val_accuracy: 0.4281 - val_loss: 0.8173\n",
            "Epoch 67/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4524 - loss: 0.8119 - val_accuracy: 0.4281 - val_loss: 0.8168\n",
            "Epoch 68/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4277 - loss: 0.8154 - val_accuracy: 0.4281 - val_loss: 0.8164\n",
            "Epoch 69/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4779 - loss: 0.7743 - val_accuracy: 0.4281 - val_loss: 0.8159\n",
            "Epoch 70/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4689 - loss: 0.7938 - val_accuracy: 0.4281 - val_loss: 0.8155\n",
            "Epoch 71/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4734 - loss: 0.7936 - val_accuracy: 0.4281 - val_loss: 0.8150\n",
            "Epoch 72/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4545 - loss: 0.8122 - val_accuracy: 0.4281 - val_loss: 0.8146\n",
            "Epoch 73/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4437 - loss: 0.8091 - val_accuracy: 0.4281 - val_loss: 0.8141\n",
            "Epoch 74/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4616 - loss: 0.7885 - val_accuracy: 0.4281 - val_loss: 0.8137\n",
            "Epoch 75/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4479 - loss: 0.8027 - val_accuracy: 0.4281 - val_loss: 0.8132\n",
            "Epoch 76/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4585 - loss: 0.7849 - val_accuracy: 0.4281 - val_loss: 0.8128\n",
            "Epoch 77/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4737 - loss: 0.7846 - val_accuracy: 0.4250 - val_loss: 0.8123\n",
            "Epoch 78/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4611 - loss: 0.7873 - val_accuracy: 0.4250 - val_loss: 0.8118\n",
            "Epoch 79/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4655 - loss: 0.7880 - val_accuracy: 0.4250 - val_loss: 0.8114\n",
            "Epoch 80/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4751 - loss: 0.7872 - val_accuracy: 0.4250 - val_loss: 0.8109\n",
            "Epoch 81/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4554 - loss: 0.7963 - val_accuracy: 0.4250 - val_loss: 0.8105\n",
            "Epoch 82/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4496 - loss: 0.7980 - val_accuracy: 0.4250 - val_loss: 0.8100\n",
            "Epoch 83/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4388 - loss: 0.7933 - val_accuracy: 0.4250 - val_loss: 0.8096\n",
            "Epoch 84/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4492 - loss: 0.8028 - val_accuracy: 0.4219 - val_loss: 0.8091\n",
            "Epoch 85/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4562 - loss: 0.7952 - val_accuracy: 0.4219 - val_loss: 0.8087\n",
            "Epoch 86/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4547 - loss: 0.7874 - val_accuracy: 0.4219 - val_loss: 0.8082\n",
            "Epoch 87/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4672 - loss: 0.7850 - val_accuracy: 0.4219 - val_loss: 0.8078\n",
            "Epoch 88/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4622 - loss: 0.7793 - val_accuracy: 0.4219 - val_loss: 0.8073\n",
            "Epoch 89/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4586 - loss: 0.7880 - val_accuracy: 0.4219 - val_loss: 0.8069\n",
            "Epoch 90/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4564 - loss: 0.7788 - val_accuracy: 0.4219 - val_loss: 0.8064\n",
            "Epoch 91/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4618 - loss: 0.7866 - val_accuracy: 0.4219 - val_loss: 0.8060\n",
            "Epoch 92/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4554 - loss: 0.8026 - val_accuracy: 0.4219 - val_loss: 0.8055\n",
            "Epoch 93/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4576 - loss: 0.7833 - val_accuracy: 0.4219 - val_loss: 0.8051\n",
            "Epoch 94/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4507 - loss: 0.7937 - val_accuracy: 0.4219 - val_loss: 0.8047\n",
            "Epoch 95/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4382 - loss: 0.7950 - val_accuracy: 0.4219 - val_loss: 0.8042\n",
            "Epoch 96/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4630 - loss: 0.7725 - val_accuracy: 0.4250 - val_loss: 0.8038\n",
            "Epoch 97/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4456 - loss: 0.7950 - val_accuracy: 0.4250 - val_loss: 0.8033\n",
            "Epoch 98/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4469 - loss: 0.7896 - val_accuracy: 0.4250 - val_loss: 0.8029\n",
            "Epoch 99/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4866 - loss: 0.7685 - val_accuracy: 0.4250 - val_loss: 0.8024\n",
            "Epoch 100/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4687 - loss: 0.7775 - val_accuracy: 0.4250 - val_loss: 0.8020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
            "Testing Accuracy: 0.425\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.94      0.59       141\n",
            "           1       0.27      0.02      0.03       179\n",
            "\n",
            "    accuracy                           0.42       320\n",
            "   macro avg       0.35      0.48      0.31       320\n",
            "weighted avg       0.34      0.42      0.28       320\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Prediction: Bad Quality\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data_url = \"/content/winequality-red.csv\"\n",
        "df = pd.read_csv(data_url)\n",
        "\n",
        "# Preprocessing\n",
        "y = df['quality']\n",
        "X = df.drop(columns=['quality'])\n",
        "y = np.where(y >= 6, 1, 0)  # Convert to binary classification\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build ANN Model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(20, activation='relu'),\n",
        "    keras.layers.Dense(25, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save model\n",
        "model.save(\"wine_quality_model.h5\")\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Testing Accuracy: {accuracy}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Precision, Recall, F1-score\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Deploy model\n",
        "loaded_model = keras.models.load_model(\"wine_quality_model.h5\")\n",
        "def predict_wine_quality(sample):\n",
        "    sample = scaler.transform([sample])\n",
        "    prediction = loaded_model.predict(sample)\n",
        "    return \"Good Quality\" if prediction > 0.5 else \"Bad Quality\"\n",
        "\n",
        "# Example Prediction\n",
        "sample_data = X_test[0]\n",
        "print(\"Sample Prediction:\", predict_wine_quality(sample_data))"
      ]
    }
  ]
}